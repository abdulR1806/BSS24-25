{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnbW2oCTsfKDFxH+b0E8Bk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdulR1806/BSS24-25/blob/main/notebook_yield_branch_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Load your Data ---\n",
        "# Assume 'df' is your main DataFrame containing the data from the first image.\n",
        "# Replace this with your actual data loading (e.g., pd.read_csv, pd.read_excel)\n",
        "# Example using dummy data based on the structure:\n",
        "data = {\n",
        "    'Periode': pd.to_datetime(['2023-01-31', '2023-01-31', '2023-01-31', '2023-01-31', '2023-02-28', '2023-02-28']),\n",
        "    'Branch': ['Branch A', 'Branch B', 'Branch A', 'Branch C', 'Branch B', 'Branch A'],\n",
        "    'Branch_Flag': ['Flag1', 'Flag2', 'Flag1', 'Flag3', 'Flag2', 'Flag1'],\n",
        "    'ID': ['ID001', 'ID002', 'ID003', 'ID004', 'ID005', 'ID006'],\n",
        "    'DPD90_Amt': [0, 5000, 1000, 0, 8000, 0],\n",
        "    'NEA': [100000, 150000, 80000, 200000, 160000, 120000],\n",
        "    'Int_Branch': [1000, 1200, 900, 1500, 1300, 1100],\n",
        "    'AEA': [95000, 140000, 78000, 190000, 155000, 115000],\n",
        "    'RSC_Amt': [0, 10000, 0, 5000, 15000, 0],\n",
        "    'SM_Amt': [20000, 30000, 15000, 40000, 35000, 25000],\n",
        "    'NonSM_Amt': [80000, 110000, 65000, 155000, 110000, 90000],\n",
        "    'War_Amt': [500, 600, 400, 700, 650, 550],\n",
        "    'Pre_Covid_Amt': [100000, 140000, 80000, 195000, 145000, 120000],\n",
        "    'Post_Covid_Amt': [0, 10000, 0, 5000, 15000, 0],\n",
        "    'OS_LTV': [70000, 90000, 60000, 120000, 100000, 80000],\n",
        "    'MARKET VALUE': [100000, 110000, 90000, 150000, 130000, 100000], # Note the space in the name\n",
        "    'DPD30_Amt': [5000, 6000, 2000, 3000, 9000, 1000],\n",
        "    'War_Amt_Ori': [550, 650, 450, 750, 700, 600]\n",
        "    # Add other columns as needed from your first image\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# It's often easier if column names don't have spaces. Rename if possible:\n",
        "if 'MARKET VALUE' in df.columns:\n",
        "    df = df.rename(columns={'MARKET VALUE': 'MARKET_VALUE'})\n",
        "    market_value_col = 'MARKET_VALUE'\n",
        "else:\n",
        "    # Handle case where renaming didn't happen or wasn't needed\n",
        "    market_value_col = 'MARKET VALUE' if 'MARKET VALUE' in df.columns else 'MARKET_VALUE'\n",
        "\n",
        "\n",
        "# --- 2. Define Columns to Aggregate ---\n",
        "# List all columns mentioned in the formulas that need to be summed per branch\n",
        "aggregation_cols = [\n",
        "    'DPD90_Amt', 'NEA', 'Int_Branch', 'AEA', 'RSC_Amt', 'SM_Amt',\n",
        "    'NonSM_Amt', 'War_Amt', 'Pre_Covid_Amt', 'Post_Covid_Amt',\n",
        "    'OS_LTV', market_value_col, 'DPD30_Amt', 'War_Amt_Ori'\n",
        "]\n",
        "\n",
        "# --- 3. Group by Branch and Aggregate ---\n",
        "# Calculate the sum of the necessary columns for each branch\n",
        "# Using .reset_index() makes 'Branch' a column again, which can be convenient\n",
        "branch_aggregates = df.groupby('Branch')[aggregation_cols].sum().reset_index()\n",
        "\n",
        "# --- 4. Define Safe Division Function ---\n",
        "# This function replicates the IFERROR(calculation, 0) logic\n",
        "def safe_divide(numerator, denominator):\n",
        "    \"\"\"Performs division, returning 0 if denominator is 0 or NaN, or if numerator is NaN.\"\"\"\n",
        "    # Ensure inputs work correctly even if they are single numbers from aggregation\n",
        "    num = pd.Series(numerator)\n",
        "    den = pd.Series(denominator)\n",
        "    result = pd.Series(np.zeros(len(num)), index=num.index) # Initialize with zeros\n",
        "    # Create a mask for valid division (denominator > 0 and not NaN, numerator not NaN)\n",
        "    valid_mask = (den != 0) & (den.notna()) & (num.notna())\n",
        "    # Perform division only for valid entries\n",
        "    result[valid_mask] = num[valid_mask] / den[valid_mask]\n",
        "    return result\n",
        "\n",
        "# --- 5. Calculate Metrics per Branch ---\n",
        "calculated_metrics = pd.DataFrame()\n",
        "calculated_metrics['Branch'] = branch_aggregates['Branch'] # Start with the Branch column\n",
        "\n",
        "# Apply formulas using the aggregated data and safe_divide\n",
        "calculated_metrics['NPL'] = safe_divide(branch_aggregates['DPD90_Amt'], branch_aggregates['NEA'])\n",
        "calculated_metrics['Yield'] = safe_divide(branch_aggregates['Int_Branch'], branch_aggregates['AEA']) * 12\n",
        "calculated_metrics['Restructured'] = safe_divide(branch_aggregates['RSC_Amt'], branch_aggregates['NEA'])\n",
        "calculated_metrics['S_Merdeka'] = safe_divide(branch_aggregates['SM_Amt'], branch_aggregates['NEA'])\n",
        "calculated_metrics['NonSM'] = safe_divide(branch_aggregates['NonSM_Amt'], branch_aggregates['NEA'])\n",
        "calculated_metrics['War'] = safe_divide(branch_aggregates['War_Amt'], branch_aggregates['AEA']) * 12\n",
        "calculated_metrics['Pre_Covid'] = safe_divide(branch_aggregates['Pre_Covid_Amt'], branch_aggregates['NEA'])\n",
        "calculated_metrics['Post_Covid'] = safe_divide(branch_aggregates['Post_Covid_Amt'], branch_aggregates['NEA'])\n",
        "calculated_metrics['LTV%'] = safe_divide(branch_aggregates['OS_LTV'], branch_aggregates[market_value_col])\n",
        "calculated_metrics['30+'] = safe_divide(branch_aggregates['DPD30_Amt'], branch_aggregates['NEA'])\n",
        "calculated_metrics['WAR ORI'] = safe_divide(branch_aggregates['War_Amt_Ori'], branch_aggregates['AEA']) * 12\n",
        "\n",
        "# --- 6. Display Results ---\n",
        "# Set Branch as the index for clearer output\n",
        "calculated_metrics = calculated_metrics.set_index('Branch')\n",
        "\n",
        "# Optional: Reorder columns based on the 'Solve Order' if desired\n",
        "solve_order_cols = ['NPL', 'Yield', 'Restructured', 'S_Merdeka', 'NonSM', 'War',\n",
        "                    'Pre_Covid', 'Post_Covid', 'LTV%', '30+', 'WAR ORI']\n",
        "# Ensure all calculated columns exist before reordering\n",
        "existing_cols = [col for col in solve_order_cols if col in calculated_metrics.columns]\n",
        "calculated_metrics = calculated_metrics[existing_cols]\n",
        "\n",
        "\n",
        "print(\"Calculated Metrics Grouped by Branch:\")\n",
        "print(calculated_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iNkodpNBKFD",
        "outputId": "7893f4fb-f371-4005-8c91-a74683ab4353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated Metrics Grouped by Branch:\n",
            "               NPL     Yield  Restructured  S_Merdeka     NonSM       War  \\\n",
            "Branch                                                                      \n",
            "Branch A  0.003333  0.125000      0.000000   0.200000  0.783333  0.060417   \n",
            "Branch B  0.041935  0.101695      0.080645   0.209677  0.709677  0.050847   \n",
            "Branch C  0.000000  0.094737      0.025000   0.200000  0.775000  0.044211   \n",
            "\n",
            "          Pre_Covid  Post_Covid      LTV%       30+   WAR ORI  \n",
            "Branch                                                         \n",
            "Branch A   1.000000    0.000000  0.724138  0.026667  0.066667  \n",
            "Branch B   0.919355    0.080645  0.791667  0.048387  0.054915  \n",
            "Branch C   0.975000    0.025000  0.800000  0.015000  0.047368  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 0. Shared Setup & Data Loading ---\n",
        "# Assume 'df' is your main DataFrame with all necessary columns.\n",
        "\n",
        "# Example using dummy data (ensure all relevant columns are present):\n",
        "data = {\n",
        "    'Periode': pd.to_datetime(['2023-01-31', '2023-01-31', '2023-01-31', '2023-01-31', '2023-02-28', '2023-02-28', '2023-03-31', '2023-03-31', '2023-01-31',\n",
        "                               '2023-02-28', '2023-02-28', '2023-03-31']), # Added more data for next month calc\n",
        "    'Branch': ['Branch A', 'Branch B', 'Branch A', 'Branch C', 'Branch B', 'Branch A', 'Branch A', 'Branch B', 'Branch A',\n",
        "               'Branch A', 'Branch C', 'Branch B'], # Added more data\n",
        "    'Type':   ['Type X', 'Type Y', 'Type Y', 'Type X', 'Type Y', 'Type X', 'Type X', 'Type Y', 'Type X',\n",
        "               'Type Y', 'Type X', 'Type Y'], # Added more data\n",
        "    'CIF_Open_Date': pd.to_datetime(['2022-05-10', '2021-11-20', '2022-08-01', '2022-01-15', '2021-12-01', '2023-01-05', '2022-06-30', '2023-02-10', '2021-09-15',\n",
        "                                     '2022-03-10', '2023-01-20','2022-09-01']), # Added more data\n",
        "    'Plafond_Tier': ['Tier 1', 'Tier 2', 'Tier 1', 'Tier 3', 'Tier 2', 'Tier 1', 'Tier 2', 'Tier 2', 'Tier 3',\n",
        "                     'Tier 1', 'Tier 3', 'Tier 2'], # Added more data\n",
        "    'Interest_Tier': ['Low', 'Medium', 'Low', 'High', 'Medium', 'Low', 'Medium', 'Low', 'High',\n",
        "                      'Medium', 'High', 'Low'], # Interest rate tiers\n",
        "    'ID': [f'ID{i:03d}' for i in range(1, 13)],\n",
        "    'DPD90_Amt': [0, 5000, 1000, 0, 8000, 0, 200, 6000, 50, 100, 0, 7500],\n",
        "    'NEA': [100000, 150000, 80000, 200000, 160000, 120000, 110000, 140000, 90000, 85000, 210000, 145000],\n",
        "    'Int_Branch': [1000, 1200, 900, 1500, 1300, 1100, 1050, 1150, 950, 800, 1600, 1180],\n",
        "    'AEA': [95000, 140000, 78000, 190000, 155000, 115000, 108000, 135000, 88000, 82000, 205000, 142000],\n",
        "    'RSC_Amt': [0, 10000, 0, 5000, 15000, 0, 1000, 8000, 200, 0, 6000, 9000],\n",
        "    'SM_Amt': [20000, 30000, 15000, 40000, 35000, 25000, 22000, 28000, 18000, 16000, 45000, 29000],\n",
        "    'NonSM_Amt': [80000, 110000, 65000, 155000, 110000, 90000, 87000, 104000, 71800, 69000, 159000, 107000],\n",
        "    'War_Amt': [500, 600, 400, 700, 650, 550, 520, 580, 480, 450, 720, 590],\n",
        "    'Pre_Covid_Amt': [100000, 140000, 80000, 195000, 145000, 120000, 109000, 132000, 90000, 85000, 204000, 136000],\n",
        "    'Post_Covid_Amt': [0, 10000, 0, 5000, 15000, 0, 1000, 8000, 200, 0, 6000, 9000],\n",
        "    'OS_LTV': [70000, 90000, 60000, 120000, 100000, 80000, 75000, 85000, 65000, 60000, 130000, 90000],\n",
        "    'MARKET VALUE': [100000, 110000, 90000, 150000, 130000, 100000, 105000, 100000, 95000, 90000, 160000, 110000],\n",
        "    'DPD30_Amt': [5000, 6000, 2000, 3000, 9000, 1000, 1500, 7000, 800, 900, 3500, 8000],\n",
        "    'War_Amt_Ori': [550, 650, 450, 750, 700, 600, 570, 630, 500, 480, 780, 610]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# --- Basic Prep (as before) ---\n",
        "if 'Type' not in df.columns: raise ValueError(\"Missing 'Type' column.\")\n",
        "if 'Plafond_Tier' not in df.columns: raise ValueError(\"Missing 'Plafond_Tier' column.\")\n",
        "if 'Interest_Tier' not in df.columns: raise ValueError(\"Missing 'Interest_Tier' column.\")\n",
        "cif_date_col = 'CIF_Open_Date'\n",
        "if cif_date_col not in df.columns: raise ValueError(f\"Missing '{cif_date_col}' column.\")\n",
        "\n",
        "df['Periode'] = pd.to_datetime(df['Periode']) # Ensure Periode is datetime\n",
        "df[cif_date_col] = pd.to_datetime(df[cif_date_col], errors='coerce')\n",
        "df['CIF_Booking_Year'] = df[cif_date_col].dt.year.astype('Int64')\n",
        "df['Plafond_Tier'] = df['Plafond_Tier'].astype(str)\n",
        "df['Interest_Tier'] = df['Interest_Tier'].astype(str)\n",
        "df['Type'] = df['Type'].astype(str)\n",
        "\n",
        "if 'MARKET VALUE' in df.columns:\n",
        "    df = df.rename(columns={'MARKET VALUE': 'MARKET_VALUE'})\n",
        "    market_value_col = 'MARKET_VALUE'\n",
        "else:\n",
        "    market_value_col = 'MARKET VALUE' if 'MARKET VALUE' in df.columns else 'MARKET_VALUE'\n",
        "\n",
        "# --- Define Safe Divide & Aggregation Dict ---\n",
        "def safe_divide(numerator, denominator):\n",
        "    num = pd.Series(numerator)\n",
        "    den = pd.Series(denominator)\n",
        "    result = pd.Series(np.zeros(len(num)), index=num.index)\n",
        "    valid_mask = (den != 0) & (den.notna()) & (num.notna())\n",
        "    result[valid_mask] = num[valid_mask] / den[valid_mask]\n",
        "    if len(result) == 1: return result.iloc[0]\n",
        "    return result\n",
        "\n",
        "aggregation_cols_sum = ['DPD90_Amt', 'NEA', 'Int_Branch', 'AEA', 'RSC_Amt', 'SM_Amt', 'NonSM_Amt', 'War_Amt', 'Pre_Covid_Amt', 'Post_Covid_Amt', 'OS_LTV', market_value_col, 'DPD30_Amt', 'War_Amt_Ori']\n",
        "agg_dict = {col: 'sum' for col in aggregation_cols_sum}\n",
        "agg_dict['ID'] = 'count'\n",
        "\n",
        "# --- Calculate Period Totals ---\n",
        "period_totals = df.groupby('Periode')['NEA'].sum().reset_index()\n",
        "period_totals = period_totals.rename(columns={'NEA': 'Total_NEA_Period'})\n",
        "\n",
        "# --- Function to Calculate Metrics ---\n",
        "def calculate_metrics_grouped(df_grouped, grouping_cols):\n",
        "    # Ensure Total_NEA_Period is present after merge\n",
        "    if 'Total_NEA_Period' not in df_grouped.columns:\n",
        "         # This might happen if called before merging period_totals\n",
        "         raise ValueError(\"Total_NEA_Period column missing in grouped data before metric calculation.\")\n",
        "\n",
        "    calculated_metrics = pd.DataFrame()\n",
        "    for col in grouping_cols:\n",
        "        calculated_metrics[col] = df_grouped[col]\n",
        "\n",
        "    # Calculate metrics... (same calculation logic as before)\n",
        "    calculated_metrics['NPL'] = safe_divide(df_grouped['DPD90_Amt'], df_grouped['NEA'])\n",
        "    calculated_metrics['Yield'] = safe_divide(df_grouped['Int_Branch'], df_grouped['AEA']) * 12\n",
        "    calculated_metrics['Restructured'] = safe_divide(df_grouped['RSC_Amt'], df_grouped['NEA'])\n",
        "    calculated_metrics['S_Merdeka'] = safe_divide(df_grouped['SM_Amt'], df_grouped['NEA'])\n",
        "    calculated_metrics['NonSM'] = safe_divide(df_grouped['NonSM_Amt'], df_grouped['NEA'])\n",
        "    calculated_metrics['War'] = safe_divide(df_grouped['War_Amt'], df_grouped['AEA']) * 12\n",
        "    calculated_metrics['Pre_Covid_Ratio'] = safe_divide(df_grouped['Pre_Covid_Amt'], df_grouped['NEA'])\n",
        "    calculated_metrics['Post_Covid_Ratio'] = safe_divide(df_grouped['Post_Covid_Amt'], df_grouped['NEA'])\n",
        "    calculated_metrics['LTV%'] = safe_divide(df_grouped['OS_LTV'], df_grouped[market_value_col])\n",
        "    calculated_metrics['30+'] = safe_divide(df_grouped['DPD30_Amt'], df_grouped['NEA'])\n",
        "    calculated_metrics['WAR ORI'] = safe_divide(df_grouped['War_Amt_Ori'], df_grouped['AEA']) * 12\n",
        "    calculated_metrics['Sum_NEA'] = df_grouped['NEA']\n",
        "    calculated_metrics['Sum_RSC_Amt'] = df_grouped['RSC_Amt']\n",
        "    calculated_metrics['Sum_Pre_Covid_Amt'] = df_grouped['Pre_Covid_Amt']\n",
        "    calculated_metrics['Percentage_NEA_of_Total'] = safe_divide(df_grouped['NEA'], df_grouped['Total_NEA_Period']) * 100\n",
        "    calculated_metrics['Count_of_ID'] = df_grouped['Count_of_ID']\n",
        "    return calculated_metrics\n",
        "\n",
        "# --- Generate the 3 Pivoted DataFrames (A, B, C as before) ---\n",
        "\n",
        "# A: Pivoted by Type\n",
        "grouping_keys_type = ['Branch', 'Periode', 'Type']\n",
        "branch_period_type_aggregates = df.groupby(grouping_keys_type).agg(agg_dict).reset_index()\n",
        "branch_period_type_aggregates = branch_period_type_aggregates.rename(columns={'ID': 'Count_of_ID'})\n",
        "branch_period_type_aggregates = pd.merge(branch_period_type_aggregates, period_totals, on='Periode', how='left')\n",
        "calculated_metrics_by_type = calculate_metrics_grouped(branch_period_type_aggregates, grouping_keys_type)\n",
        "calculated_metrics_by_type = calculated_metrics_by_type.set_index(grouping_keys_type)\n",
        "df_pivoted = calculated_metrics_by_type.unstack(level='Type')\n",
        "df_pivoted.columns = ['_'.join(col).strip().replace(' ', '_') for col in df_pivoted.columns.values]\n",
        "\n",
        "# B: Pivoted by Year\n",
        "grouping_keys_year = ['Branch', 'Periode', 'CIF_Booking_Year']\n",
        "branch_period_year_aggregates = df.dropna(subset=['CIF_Booking_Year']).groupby(grouping_keys_year).agg(agg_dict).reset_index()\n",
        "branch_period_year_aggregates = branch_period_year_aggregates.rename(columns={'ID': 'Count_of_ID'})\n",
        "branch_period_year_aggregates = pd.merge(branch_period_year_aggregates, period_totals, on='Periode', how='left')\n",
        "calculated_metrics_by_year = calculate_metrics_grouped(branch_period_year_aggregates, grouping_keys_year)\n",
        "calculated_metrics_by_year['CIF_Booking_Year'] = calculated_metrics_by_year['CIF_Booking_Year'].astype(int)\n",
        "calculated_metrics_by_year = calculated_metrics_by_year.set_index(grouping_keys_year)\n",
        "pivoted_by_year_metrics = calculated_metrics_by_year.unstack(level='CIF_Booking_Year')\n",
        "pivoted_by_year_metrics.columns = [f'{metric}_{year}' for metric, year in pivoted_by_year_metrics.columns]\n",
        "\n",
        "# C: Pivoted by Plafond Tier\n",
        "plafond_col = 'Plafond_Tier'\n",
        "grouping_keys_plafond = ['Branch', 'Periode', plafond_col]\n",
        "branch_period_plafond_aggregates = df.dropna(subset=[plafond_col]).groupby(grouping_keys_plafond).agg(agg_dict).reset_index()\n",
        "branch_period_plafond_aggregates = branch_period_plafond_aggregates.rename(columns={'ID': 'Count_of_ID'})\n",
        "branch_period_plafond_aggregates = pd.merge(branch_period_plafond_aggregates, period_totals, on='Periode', how='left')\n",
        "calculated_metrics_by_plafond = calculate_metrics_grouped(branch_period_plafond_aggregates, grouping_keys_plafond)\n",
        "calculated_metrics_by_plafond = calculated_metrics_by_plafond.set_index(grouping_keys_plafond)\n",
        "pivoted_by_plafond_metrics = calculated_metrics_by_plafond.unstack(level=plafond_col)\n",
        "pivoted_by_plafond_metrics.columns = [f'{metric}_{tier.replace(\" \", \"_\")}' for metric, tier in pivoted_by_plafond_metrics.columns]\n",
        "\n",
        "# D: Pivoted by Interest Tier\n",
        "interest_col = 'Interest_Tier'\n",
        "grouping_keys_interest = ['Branch', 'Periode', interest_col]\n",
        "branch_period_interest_aggregates = df.dropna(subset=[interest_col]).groupby(grouping_keys_interest).agg(agg_dict).reset_index()\n",
        "branch_period_interest_aggregates = branch_period_interest_aggregates.rename(columns={'ID': 'Count_of_ID'})\n",
        "branch_period_interest_aggregates = pd.merge(branch_period_interest_aggregates, period_totals, on='Periode', how='left')\n",
        "calculated_metrics_by_interest = calculate_metrics_grouped(branch_period_interest_aggregates, grouping_keys_interest)\n",
        "calculated_metrics_by_interest = calculated_metrics_by_interest.set_index(grouping_keys_interest)\n",
        "pivoted_by_interest_metrics = calculated_metrics_by_interest.unstack(level=interest_col)\n",
        "pivoted_by_interest_metrics.columns = [f'{metric}_{tier.replace(\" \", \"_\")}' for metric, tier in pivoted_by_interest_metrics.columns]\n",
        "\n",
        "# --- E: Combine the four pivoted DataFrames ---\n",
        "combined_df_step1 = pd.merge(df_pivoted, pivoted_by_year_metrics, left_index=True, right_index=True, how='outer')\n",
        "combined_df_step2 = pd.merge(combined_df_step1, pivoted_by_plafond_metrics, left_index=True, right_index=True, how='outer')\n",
        "final_combined_df = pd.merge(combined_df_step2, pivoted_by_interest_metrics, left_index=True, right_index=True, how='outer')\n",
        "print(f\"Shape of combined pivoted data: {final_combined_df.shape}\")\n",
        "\n",
        "\n",
        "# --- F: Generate Original Aggregated Data (Grouped only by Branch, Period) ---\n",
        "print(\"\\n--- Generating Original Aggregated Data (Branch, Periode) ---\")\n",
        "grouping_keys_overall = ['Branch', 'Periode']\n",
        "overall_aggregates = df.groupby(grouping_keys_overall).agg(agg_dict).reset_index()\n",
        "overall_aggregates = overall_aggregates.rename(columns={'ID': 'Count_of_ID'})\n",
        "# Merge period totals needed for percentage calculation\n",
        "overall_aggregates = pd.merge(overall_aggregates, period_totals, on='Periode', how='left')\n",
        "\n",
        "# Calculate metrics for the overall group\n",
        "original_aggregated_metrics = calculate_metrics_grouped(overall_aggregates, grouping_keys_overall)\n",
        "\n",
        "# Rename columns to avoid clashes with pivoted columns\n",
        "original_aggregated_metrics.columns = [f\"{col}_Overall\" if col not in grouping_keys_overall else col for col in original_aggregated_metrics.columns]\n",
        "\n",
        "# Set index for merging\n",
        "original_aggregated_metrics = original_aggregated_metrics.set_index(grouping_keys_overall)\n",
        "print(f\"Shape of original aggregated data: {original_aggregated_metrics.shape}\")\n",
        "\n",
        "\n",
        "# --- G: Merge Original Aggregated Data with Combined Pivoted Data ---\n",
        "print(\"\\n--- Merging Original Aggregated Data with Pivoted Data ---\")\n",
        "final_dataset = pd.merge(\n",
        "    final_combined_df,\n",
        "    original_aggregated_metrics,\n",
        "    left_index=True,\n",
        "    right_index=True,\n",
        "    how='left' # Keep all rows from the pivoted table, add overall metrics\n",
        ")\n",
        "print(f\"Shape after final merge: {final_dataset.shape}\")\n",
        "\n",
        "\n",
        "# --- H: Create Target Variables ---\n",
        "print(\"\\n--- Creating Target Variables ---\")\n",
        "# Sort by Branch then Period to ensure correct shifting\n",
        "final_dataset = final_dataset.sort_index(level=['Branch', 'Periode'])\n",
        "\n",
        "# Shift the 'Yield_Overall' column within each Branch group\n",
        "final_dataset['Yield_Overall_NextMonth'] = final_dataset.groupby('Branch')['Yield_Overall'].shift(-1)\n",
        "final_dataset['Yield_Decrease_Next_Month'] = (final_dataset['Yield_Overall_NextMonth'] < final_dataset['Yield_Overall']).astype(int)\n",
        "\n",
        "# Shift the 'NPL_Overall' column (or '30+_Overall' if preferred)\n",
        "final_dataset['NPL_Overall_NextMonth'] = final_dataset.groupby('Branch')['NPL_Overall'].shift(-1)\n",
        "final_dataset['DPD_Increase_Next_Month'] = (final_dataset['NPL_Overall_NextMonth'] > final_dataset['NPL_Overall']).astype(int)\n",
        "\n",
        "# Optionally drop the intermediate shifted columns\n",
        "# final_dataset = final_dataset.drop(columns=['Yield_Overall_NextMonth', 'NPL_Overall_NextMonth'])\n",
        "\n",
        "# --- I: Display Final Result ---\n",
        "print(\"\\n--- Final Dataset with Target Variables ---\")\n",
        "# Select key columns including new targets to display snippet\n",
        "display_cols = list(final_dataset.filter(like='_Overall').columns) + ['Yield_Decrease_Next_Month', 'DPD_Increase_Next_Month']\n",
        "print(final_dataset[display_cols].to_string())\n",
        "\n",
        "# For full view:\n",
        "# print(final_dataset.info())\n",
        "# print(final_dataset.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9Aqp7K9BSAT",
        "outputId": "7ecad374-3bae-4314-dec0-e9af36f847dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of combined pivoted data: (8, 128)\n",
            "\n",
            "--- Generating Original Aggregated Data (Branch, Periode) ---\n",
            "Shape of original aggregated data: (8, 16)\n",
            "\n",
            "--- Merging Original Aggregated Data with Pivoted Data ---\n",
            "Shape after final merge: (8, 144)\n",
            "\n",
            "--- Creating Target Variables ---\n",
            "\n",
            "--- Final Dataset with Target Variables ---\n",
            "                     NPL_Overall  Yield_Overall  Restructured_Overall  S_Merdeka_Overall  NonSM_Overall  War_Overall  Pre_Covid_Ratio_Overall  Post_Covid_Ratio_Overall  LTV%_Overall  30+_Overall  WAR ORI_Overall  Sum_NEA_Overall  Sum_RSC_Amt_Overall  Sum_Pre_Covid_Amt_Overall  Percentage_NEA_of_Total_Overall  Count_of_ID_Overall  Yield_Overall_NextMonth  NPL_Overall_NextMonth  Yield_Decrease_Next_Month  DPD_Increase_Next_Month\n",
            "Branch   Periode                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
            "Branch A 2023-01-31     0.003889       0.131034              0.000741           0.196296       0.802963     0.063448                 1.000000                  0.000741      0.684211     0.028889         0.068966           270000                  200                     270000                        43.548387                    3                 0.115736               0.000488                          1                        0\n",
            "         2023-02-28     0.000488       0.115736              0.000000           0.200000       0.775610     0.060914                 1.000000                  0.000000      0.736842     0.009268         0.065787           205000                    0                     205000                        35.652174                    2                 0.116667               0.001818                          0                        1\n",
            "         2023-03-31     0.001818       0.116667              0.009091           0.200000       0.790909     0.057778                 0.990909                  0.009091      0.714286     0.013636         0.063333           110000                 1000                     109000                        27.848101                    1                      NaN                    NaN                          0                        0\n",
            "Branch B 2023-01-31     0.033333       0.102857              0.066667           0.200000       0.733333     0.051429                 0.933333                  0.066667      0.818182     0.040000         0.055714           150000                10000                     140000                        24.193548                    1                 0.100645               0.050000                          1                        1\n",
            "         2023-02-28     0.050000       0.100645              0.093750           0.218750       0.687500     0.050323                 0.906250                  0.093750      0.769231     0.056250         0.054194           160000                15000                     145000                        27.826087                    1                 0.100939               0.047368                          0                        0\n",
            "         2023-03-31     0.047368       0.100939              0.059649           0.200000       0.740351     0.050686                 0.940351                  0.059649      0.833333     0.052632         0.053718           285000                17000                     268000                        72.151899                    2                      NaN                    NaN                          0                        0\n",
            "Branch C 2023-01-31     0.000000       0.094737              0.025000           0.200000       0.775000     0.044211                 0.975000                  0.025000      0.800000     0.015000         0.047368           200000                 5000                     195000                        32.258065                    1                 0.093659               0.000000                          1                        0\n",
            "         2023-02-28     0.000000       0.093659              0.028571           0.214286       0.757143     0.042146                 0.971429                  0.028571      0.812500     0.016667         0.045659           210000                 6000                     204000                        36.521739                    1                      NaN                    NaN                          0                        0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_dataset.columns.to_list())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIuPiGG2b7AU",
        "outputId": "b6f7d1fe-4d6f-4f6b-de3c-cedd4bda2715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "148"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "29dz5RGocIUW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}